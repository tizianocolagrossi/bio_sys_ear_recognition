{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphological trasformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "img_color = cv2.imread('.\\\\AMI\\\\003_zoom_ear.jpg')\n",
    "img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "for i in range(0, 3):\n",
    "    dilated = cv2.dilate(img_gray.copy(), None, iterations=i + 1)\n",
    "    blur_dilated = cv2.GaussianBlur(dilated,(21,21),1)\n",
    "    cv2.imshow(\"Dilated {} times\".format(i + 1), dilated)\n",
    "    cv2.imshow(\"Dilated {} times blur\".format(i + 1), blur_dilated)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "img_color = cv2.imread('.\\\\AMI\\\\003_zoom_ear.jpg')\n",
    "img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kernelSizes = [(3, 3), (5, 5), (7, 7), (9,9), (11,11)]\n",
    "for kernelSize in kernelSizes:\n",
    "\t# construct a rectangular kernel from the current size and then\n",
    "\t# apply an \"opening\" operation\n",
    "\tkernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernelSize)\n",
    "\topening = cv2.morphologyEx(img_gray, cv2.MORPH_OPEN, kernel)\n",
    "\tcv2.imshow(\"Opening: ({}, {})\".format(\n",
    "\t\tkernelSize[0], kernelSize[1]), opening)\n",
    "\tcv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "img_color = cv2.imread('.\\\\AMI\\\\003_zoom_ear.jpg')\n",
    "img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kernelSizes = [(3, 3), (5, 5), (7, 7), (9,9), (11,11)]\n",
    "# loop over the kernels sizes again\n",
    "for kernelSize in kernelSizes:\n",
    "\t# construct a rectangular kernel form the current size, but this\n",
    "\t# time apply a \"closing\" operation\n",
    "\tkernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernelSize)\n",
    "\tclosing = cv2.morphologyEx(img_gray, cv2.MORPH_CLOSE, kernel)\n",
    "\tcv2.imshow(\"Closing: ({}, {})\".format(\n",
    "\t\tkernelSize[0], kernelSize[1]), closing)\n",
    "\tcv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top hat/white hat and black hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "img_color = cv2.imread('.\\\\AMI\\\\003_zoom_ear.jpg')\n",
    "img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# construct a rectangular kernel (13x5) and apply a blackhat\n",
    "# operation which enables us to find dark regions on a light\n",
    "# background\n",
    "rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))\n",
    "blackhat = cv2.morphologyEx(img_gray, cv2.MORPH_BLACKHAT, rectKernel)\n",
    "\n",
    "# similarly, a tophat (also called a \"whitehat\") operation will\n",
    "# enable us to find light regions on a dark background\n",
    "tophat = cv2.morphologyEx(img_gray, cv2.MORPH_TOPHAT, rectKernel)\n",
    "# show the output images\n",
    "cv2.imshow(\"Original\", img_color)\n",
    "cv2.imshow(\"Blackhat\", blackhat)\n",
    "cv2.imshow(\"Tophat\", tophat)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "img_color = cv2.imread('.\\\\AMI\\\\003_zoom_ear.jpg')\n",
    "img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "inverted = cv2.bitwise_not(img_gray)\n",
    "cv2.imshow(\"Inverted\", inverted)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "img_color = cv2.imread('.\\\\AMI\\\\003_zoom_ear.jpg')\n",
    "img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "equ = cv2.equalizeHist(img_gray)\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "cl1 = clahe.apply(img_gray)\n",
    "\n",
    "cv2.imshow(\"origi\", img_gray)\n",
    "cv2.imshow(\"equi\", equ)\n",
    "cv2.imshow(\"cl1\", cl1)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roberts edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "img_color = cv2.imread('.\\\\AMI\\\\003_zoom_ear.jpg')\n",
    "img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kernelx = np.array([[1, 0], [0, -1]])\n",
    "kernely = np.array([[0, 1], [-1, 0]])\n",
    "img_robertx = cv2.filter2D(img_gray, -1, kernelx)\n",
    "img_roberty = cv2.filter2D(img_gray, -1, kernely)\n",
    "grad = cv2.addWeighted(img_robertx, 0.5, img_roberty, 0.5, 0)\n",
    "\n",
    "cv2.imshow(\"Roberts\", grad)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prewitt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "img_color = cv2.imread('.\\\\AMI\\\\003_zoom_ear.jpg')\n",
    "img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img_gaussian = cv2.GaussianBlur(img_gray,(3,3),0)\n",
    "\n",
    "#prewitt\n",
    "kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "img_prewittx = cv2.filter2D(img_gaussian, -1, kernelx)\n",
    "img_prewitty = cv2.filter2D(img_gaussian, -1, kernely)\n",
    "prewitt = img_prewittx + img_prewitty\n",
    "\n",
    "cv2.imshow(\"Original Image\", img_color)\n",
    "cv2.imshow(\"Prewitt X\", img_prewittx)\n",
    "cv2.imshow(\"Prewitt Y\", img_prewitty)\n",
    "cv2.imshow(\"Prewitt\", prewitt)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69eb92836b941e979072a76c7fcfffe5419cca933cedd02cfafbdfca1a93358c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
